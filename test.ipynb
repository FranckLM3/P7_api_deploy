{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "class credit_scorer:\n",
    "    '''Create a object to implement credit scoring.\n",
    "    '''\n",
    "    def __init__(self, preprocess_path:str, model_path:str):\n",
    "        self.preprocessor = self.get_preprocess(preprocess_path)\n",
    "        self.clf = self.get_model(model_path)\n",
    "        self.scorer_meaning = {\n",
    "            False : 'No payement difficulties',\n",
    "            True : 'Payement difficulties'}\n",
    "    \n",
    "    def get_model(self, model_path:str):\n",
    "        '''Open the pkl file which store the model.\n",
    "        Arguments: \n",
    "            model_path: Path model with pkl extension\n",
    "        \n",
    "        Returns:\n",
    "            model: Model object\n",
    "        '''\n",
    "\n",
    "        with open(model_path,\"rb\") as f:\n",
    "            clf = pickle.load(f)\n",
    "        \n",
    "        return clf\n",
    "    \n",
    "    def get_preprocess(self, preprocess_path:str):\n",
    "        '''Open the pkl file which store the scaler.\n",
    "        Arguments: \n",
    "            scaler_path: Path scaler with pkl extension\n",
    "        \n",
    "        Returns:\n",
    "            scaler: scaler object\n",
    "        '''\n",
    "\n",
    "        with open(preprocess_path,\"rb\") as f:\n",
    "            preprocessor = pickle.load(f)\n",
    "        \n",
    "        return preprocessor\n",
    "\n",
    "    def transfrom(self, data, client_id:dict):\n",
    "        '''Preprocess the features for prediction\n",
    "        '''\n",
    "        try: \n",
    "            # Read data\n",
    "            df = data.copy()\n",
    "            df = df.replace([np.inf, -np.inf], np.nan)\n",
    "            id = client_id['id']\n",
    "            df = df[df['SK_ID_CURR'] == id]\n",
    "\n",
    "            X = df.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
    "            y = df['TARGET']\n",
    "\n",
    "            X = self.preprocessor.transform(X)\n",
    "        except: \n",
    "            print('This client is not in the database...')\n",
    "\n",
    "        return X\n",
    "\n",
    "    def make_prediction(self, features)->str:\n",
    "        '''Predicts the credit score.\n",
    "        Argument:\n",
    "            features: list\n",
    "        \n",
    "        return:\n",
    "            cluster: str\n",
    "        '''\n",
    "        if isinstance(features, str):\n",
    "            score = 'This client is not in the database...'\n",
    "        else: \n",
    "            prob = self.clf.predict_proba(features)[:, 1]\n",
    "\n",
    "            pred = (prob >= 0.47)[0]\n",
    "\n",
    "            score = self.scorer_meaning[pred]\n",
    "\n",
    "        return prob, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = credit_scorer('pipeline', 'classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Customer(BaseModel):\n",
    "    id: int\n",
    "\n",
    "m = Customer(id=100006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.dict()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('model_dataset.csv',\n",
    "                            engine='pyarrow',\n",
    "                            verbose=False,\n",
    "                            encoding='ISO-8859-1',\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = scorer.transfrom(df, m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.20800114e-01, -7.18646197e-01, -1.31255508e-01,\n",
       "        -7.11391033e-01,  1.77827361e-01, -6.53350631e-01,\n",
       "        -9.29746928e-01, -6.80187496e-01, -2.82159908e-01,\n",
       "        -1.37683173e+00,  3.69897368e-01, -4.99189427e-01,\n",
       "        -6.27087115e-02,             nan,  7.11301940e-01,\n",
       "                    nan,             nan, -3.23996515e-01,\n",
       "        -2.78010758e-01,  4.19224712e-01,  6.39370743e-01,\n",
       "                    nan,  2.40022713e-02,  5.90333964e-02,\n",
       "        -2.38361971e-01,  4.13470646e-01,  1.83629222e+00,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "        -7.18802008e-01,  8.49989625e-01,  9.13775130e-01,\n",
       "        -9.23930885e-02,  4.45289637e-01,  2.47014876e-01,\n",
       "        -1.25582614e-01,  1.89820070e+00,  1.50366660e+00,\n",
       "        -4.75521955e-01,  7.28936045e-02,  7.22653109e-01,\n",
       "         1.06703530e+00,  5.54671400e-01,  1.11928016e+00,\n",
       "         1.00425948e+00,  1.03335212e+00, -7.35142271e-01,\n",
       "         7.78409094e-04, -4.46850328e-01,  1.64426408e-01,\n",
       "         2.30844977e-01, -6.99891940e-01, -2.90241164e-01,\n",
       "         4.93309915e-01, -4.39133110e-01, -2.40426914e-01,\n",
       "        -7.29343750e-02, -6.87900613e-01, -5.36479691e-02,\n",
       "        -3.71699192e-01,  4.52787357e-02, -2.70753070e-01,\n",
       "         9.34936799e-01,  1.43390643e+00,  1.03704209e+00,\n",
       "         1.13740835e+00,  7.48044562e-01,  5.80937069e-01,\n",
       "         1.15027343e+00,  6.18833834e-01,  1.10405590e+00,\n",
       "        -3.50612803e-01, -1.02198349e-01, -4.84927742e-02,\n",
       "        -6.39066383e-01, -3.24021717e-01, -1.51216373e-01,\n",
       "        -1.66242884e-01, -1.12273361e-01,  1.34422480e+00,\n",
       "         7.77423768e-01, -1.99264456e-01, -1.30141624e-02,\n",
       "        -4.39272233e-01,  7.05265191e-02,  3.59089616e-02,\n",
       "         2.26189172e+00,  1.89875291e+00,  3.80673178e-01,\n",
       "        -1.85792186e-01,  5.87580626e-01,  1.08712461e+00,\n",
       "         6.63643141e-01,  9.40343838e-01, -6.55949487e-01,\n",
       "        -3.80763042e-01, -7.85761752e-01,             nan,\n",
       "                    nan,             nan,             nan,\n",
       "                    nan, -4.14903858e-01, -2.27614687e-01,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob, info = scorer.make_prediction(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27772680638972275"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv('dataset_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_devenv",
   "language": "python",
   "name": "datascience_devenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
